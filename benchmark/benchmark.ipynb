{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark\n",
    "\n",
    "We use a list of public datasets to benchmark all the algorithms in StreamAD. Thanks!\n",
    "\n",
    "1. AIOPS_KPI, [AIOps Challenge public dataset for KPI anomaly detection](https://github.com/NetManAIOps/KPI-Anomaly-Detection)\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import perf_counter\n",
    "from streamad.util import StreamGenerator, CustomDS\n",
    "from streamad.model import SpotDetector\n",
    "from streamad.evaluate import NumentaAwareMetircs, PointAwareMetircs, SeriesAwareMetircs\n",
    "from dataset import prepare_ds, read_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download the dataset, unzip it, and reconstruct its structure with **prepare_ds()** and load the dataset with **read_ds()**\n",
    "\n",
    "By now, **ds_name** and **file_name** are represented by\n",
    "\n",
    "```python\n",
    "\n",
    "DS = {\"AIOPS_KPI\": [\"preliminary_train\", \"finals_train\", \"finals_ground_truth\"]}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './streamad-benchmark-dataset'\n",
    "ds_name = 'AIOPS_KPI'\n",
    "prepare_ds(ds_name=ds_name,path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = read_ds(ds_name=ds_name,ds_file=\"preliminary_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_items = [\n",
    "    \"Dataset\",\n",
    "    \"Key\",\n",
    "    \"Size(#)\",\n",
    "    \"Time(s)\",\n",
    "    \"Point_Precision\",\n",
    "    \"Point_Recall\",\n",
    "    \"Point_Fbeta\",\n",
    "    \"Series_Precision\",\n",
    "    \"Series_Recall\",\n",
    "    \"Series_Fbeta\",\n",
    "    \"Numenta_Precision\",\n",
    "    \"Numenta_Recall\",\n",
    "    \"Numenta_Fbeta\",\n",
    "]\n",
    "benchmark_df = pd.DataFrame(columns=benchmark_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for key, (df, label) in dfs.items():\n",
    "\n",
    "    ds = CustomDS(df, label)\n",
    "    stream = StreamGenerator(ds.data)\n",
    "    model = SpotDetector(window_len=200)\n",
    "\n",
    "    start_time = perf_counter()\n",
    "    for x in tqdm(stream.iter_item(), total=len(ds.data)):\n",
    "        score = model.fit_score(x)\n",
    "        scores.append(score)\n",
    "\n",
    "    time = perf_counter() - start_time\n",
    "\n",
    "    benchmark_values = [ds_name, key, len(ds.data), time]\n",
    "\n",
    "    label = ds.label\n",
    "    for metric in [\n",
    "        PointAwareMetircs(),\n",
    "        SeriesAwareMetircs(),\n",
    "        NumentaAwareMetircs(),\n",
    "    ]:\n",
    "\n",
    "        # scores = np.nan_to_num(np.array(scores, dtype=float), nan=0)\n",
    "        benchmark_values.extend(list(metric.evaluate(label, scores)))\n",
    "\n",
    "    benchmark_df.loc[len(benchmark_df)] = benchmark_values\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df.to_csv('./benchamark_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('streamad')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0929cc61c31530b0dd93f4de65929aaf6e8458bcea2636b14bc2eb1d87a859e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
